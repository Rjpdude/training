base_model: meetkai/functionary-medium-v2.2
model_type: AutoModelForCausalLM
tokenizer_type: AutoTokenizer
tokenizer_config: meetkai/functionary-medium-v2.2
trust_remote_code: true
tokenizer_use_fast: true
is_mistral_derived_model: true
resize_token_embeddings_to_32x: true
load_in_8bit: true
load_in_4bit: false
strict: false

gpu_memory_limit: 79GiB
lora_on_cpu: true

rl: dpo
datasets:
  - path: argilla/ultrafeedback-binarized-preferences
    split: train
    type: chatml.argilla
dataset_prepared_path: last_run_prepared
val_set_size: 0.0
output_dir: ./qlora-out

## You can optionally freeze the entire model and unfreeze a subset of parameters
unfrozen_parameters:
 - lm_head.*
 - model.embed_tokens.*
#  - model.layers.2[0-9]+.block_sparse_moe.gate.*
#  - model.layers.2[0-9]+.block_sparse_moe.experts.*
#  - model.layers.3[0-9]+.block_sparse_moe.gate.*
#  - model.layers.3[0-9]+.block_sparse_moe.experts.*

model_config:
  output_router_logits: true

adapter: peft
lora_model_dir: NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO-adapter
hub_model_id: SiguienteGlobal/Linguistica2.0
train_on_inputs: true

default_system_message: |-
  Te llamas Lingüística. Has sido creado y entrenado de por la empresa Siguiente para interactuar con usuarios en español de manera natural y familiar.
  Tienes cualidades docentes, creativas y aplicativas para el ámbito educativo, capaz de ofrecer opciones de enseñanza para mejorar la educación en México.
  Eres firme en tu estilo de respuesta, sugieres soluciones y no solo información útil.
  Eres capaz de tomar decisiones basado en los recursos que se te permita acceso
  Ademas, de desarrollar personalidad propia perfilando al usuario para que la interacción sea natural.

sequence_len: 1024
sample_packing: false
pad_to_sequence_len: true

lora_r: 64
lora_alpha: 16
lora_dropout: 0.05
lora_target_linear: true
lora_fan_in_fan_out: false
lora_modules_to_save:
  - lm_head
  - embed_tokens
lora_target_modules:
  - gate
  - q_proj
  - k_proj
  - v_proj
  - o_proj
  - w1
  - w2
  - w3

wandb_project: Linguistica
wandb_entity:
wandb_watch:
wandb_name: siguienteia
wandb_log_model: checkpoint

hf_use_auth_token: true
save_safetensors: true

gradient_accumulation_steps: 1
micro_batch_size: 1
num_epochs: 4
optimizer: adamw_bnb_8bit
lr_scheduler: cosine
learning_rate: 0.0002

group_by_length: false
bf16: auto
fp16: true
tf32: false

gradient_checkpointing: true
early_stopping_patience:
resume_from_checkpoint:
local_rank:
logging_steps: 1
xformers_attention:
flash_attention: true

loss_watchdog_threshold: 5.0
loss_watchdog_patience: 3

warmup_steps: 10
evals_per_epoch: 4
eval_table_size:
eval_table_max_new_tokens: 128
saves_per_epoch: 1
debug:
deepspeed: deepspeed_configs/zero2.json
weight_decay: 0.0
fsdp:
fsdp_config:
special_tokens:
